{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# Sklearn libraries.\n",
    "from sklearn import datasets, linear_model, ensemble, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "from collections import Counter\n",
    "#deep learning library\n",
    "\n",
    "import json, os, re, shutil, sys, time\n",
    "import collections, itertools\n",
    "import unittest\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.\"))\n",
    "\n",
    "# utils.pretty_print_matrix uses Pandas. Configure float format here.\n",
    "import pandas as pd\n",
    "pd.set_option('float_format', lambda f: \"{0:.04f}\".format(f))\n",
    "\n",
    "# Helper libraries\n",
    "from shared_lib import utils, vocabulary, tf_embed_viz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'r')\n",
    "    for l in g:\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unzip gz file.\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "# Load JSON into dataframe.\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Used 40.925021s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = getDF('/home/legu/data/reviews_Clothing_Shoes_and_Jewelry_5.json.gz')\n",
    "end = time.time()\n",
    "print \"Time Used %fs\" %(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Exploration and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'reviewerID', u'asin', u'reviewerName', u'helpful', u'unixReviewTime',\n",
      "       u'reviewText', u'overall', u'reviewTime', u'summary'],\n",
      "      dtype='object')\n",
      "This is a great tutu and at a really great price. It doesn't look cheap at all. I'm so glad I looked on Amazon and found such an affordable tutu that isn't made poorly. A++\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1KLRMWW2FWPL4</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Amazon Customer \"cameramom\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1297468800</td>\n",
       "      <td>This is a great tutu and at a really great pri...</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>02 12, 2011</td>\n",
       "      <td>Great tutu-  not cheaply made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2G5TCU2WDFZ65</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1358553600</td>\n",
       "      <td>I bought this for my 4 yr old daughter for dan...</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>01 19, 2013</td>\n",
       "      <td>Very Cute!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1RLQXYNCMWRWN</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Carola</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1357257600</td>\n",
       "      <td>What can I say... my daughters have it in oran...</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>01 4, 2013</td>\n",
       "      <td>I have buy more than one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A8U3FAMSJVHS5</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Caromcg</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1398556800</td>\n",
       "      <td>We bought several tutus at once, and they are ...</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>04 27, 2014</td>\n",
       "      <td>Adorable, Sturdy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3GEOILWLK86XM</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>CJ</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1394841600</td>\n",
       "      <td>Thank you Halo Heaven great product for Little...</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>03 15, 2014</td>\n",
       "      <td>Grammy's Angels Love it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                 reviewerName helpful  \\\n",
       "0  A1KLRMWW2FWPL4  0000031887  Amazon Customer \"cameramom\"  [0, 0]   \n",
       "1  A2G5TCU2WDFZ65  0000031887              Amazon Customer  [0, 0]   \n",
       "2  A1RLQXYNCMWRWN  0000031887                       Carola  [0, 0]   \n",
       "3   A8U3FAMSJVHS5  0000031887                      Caromcg  [0, 0]   \n",
       "4  A3GEOILWLK86XM  0000031887                           CJ  [0, 0]   \n",
       "\n",
       "   unixReviewTime                                         reviewText  overall  \\\n",
       "0      1297468800  This is a great tutu and at a really great pri...   5.0000   \n",
       "1      1358553600  I bought this for my 4 yr old daughter for dan...   5.0000   \n",
       "2      1357257600  What can I say... my daughters have it in oran...   5.0000   \n",
       "3      1398556800  We bought several tutus at once, and they are ...   5.0000   \n",
       "4      1394841600  Thank you Halo Heaven great product for Little...   5.0000   \n",
       "\n",
       "    reviewTime                        summary  \n",
       "0  02 12, 2011  Great tutu-  not cheaply made  \n",
       "1  01 19, 2013                    Very Cute!!  \n",
       "2   01 4, 2013       I have buy more than one  \n",
       "3  04 27, 2014               Adorable, Sturdy  \n",
       "4  03 15, 2014        Grammy's Angels Love it  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df.columns\n",
    "\n",
    "print df['reviewText'][0]\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring helpfulness scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helpfulness = []\n",
    "total_votes = []\n",
    "for i in df['helpful']:\n",
    "    if i[1] == 0:\n",
    "        helpfulness.append(np.nan)\n",
    "        total_votes.append(np.nan)\n",
    "    else:\n",
    "        helpfulness.append(float(i[0])/i[1])\n",
    "        total_votes.append(i[1])\n",
    "        \n",
    "# Convert to numpy array.\n",
    "helpfulness = np.array(helpfulness)\n",
    "total_votes = np.array(total_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewerID                                           A353U0L2HAMSHV\n",
      "asin                                                     B000JD2614\n",
      "reviewerName                   Cricket \"Living life and loving it!\"\n",
      "helpful                                                      [4, 2]\n",
      "unixReviewTime                                           1234828800\n",
      "reviewText        I have been waiting for these to go on sale fo...\n",
      "overall                                                      5.0000\n",
      "reviewTime                                              02 17, 2009\n",
      "summary                                              A gift for me!\n",
      "Name: 30730, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i, row in df.iterrows():\n",
    "    helpful = row['helpful']\n",
    "    if helpful[0] > helpful[1]:\n",
    "        print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  remove the invalid entries\n",
    "helpfulness_clean = np.delete(helpfulness, 30730)\n",
    "doc = np.array(df['reviewText'])\n",
    "doc_clean = np.delete(doc, 30730)\n",
    "\n",
    "# remove the nan values\n",
    "nonnan_doc_clean = doc_clean[~np.isnan(helpfulness_clean)]\n",
    "nonnan_helpfulness_clean = helpfulness_clean[~np.isnan(helpfulness_clean)]\n",
    "y = np.reshape(nonnan_helpfulness_clean,(-1,1))\n",
    "\n",
    "#binarize\n",
    "\n",
    "y_norm = np.rint(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n",
      "For what I paid for two tutus is unbeatable anywhere!  I ordered a pink and turquios and they are vibrant and beautiful! The tutu is very full! Princess style! Not cheaply made! Not cheap materia! Obviously someone made these with love and care! I paid less than 7 bucks for a tutu I and I feel proud of my self for researching to the point of finding gold!Recommend 2-6 years!My daughter is two ! Wears size 4t and this skirt ( one size ) fit perfect and will probaly be able to accommodate her quickly growing waist for some time!\n",
      "[ 0.875]\n",
      "[ 1.]\n"
     ]
    }
   ],
   "source": [
    "print (nonnan_helpfulness_clean[0])\n",
    "print (nonnan_doc_clean[0])\n",
    "print (y[0])\n",
    "print (y_norm[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Balance the dataset and generate train/dev/test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## based on this https://beckernick.github.io/oversampling-modeling/\n",
    "#split into train and test data\n",
    "msk = np.random.rand(nonnan_doc_clean.shape[0]) <= 0.9\n",
    "\n",
    "X_train_dev = nonnan_doc_clean[msk]\n",
    "X_test = nonnan_doc_clean[~msk]\n",
    "y_train_dev = y_norm[msk]\n",
    "y_test = y_norm[~msk]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split training into train and dev\n",
    "\n",
    "msk = np.random.rand(X_train_dev.shape[0]) <= 0.89 #(8:1)\n",
    "\n",
    "X_train = X_train_dev[msk]\n",
    "X_dev = X_train_dev[~msk]\n",
    "y_train = y_train_dev[msk]\n",
    "y_dev = y_train_dev[~msk]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "ind = np.where(y_train == 0)[0]\n",
    "ind_upsamp = np.random.choice(ind,size = len(np.where(y_train == 1)[0]),replace =1)\n",
    "x_train_res= np.concatenate( [X_train[ind_upsamp] ,X_train[np.where(y_train == 1)[0]]],axis=0)\n",
    "y_train_res= np.concatenate( [y_train[ind_upsamp] ,y_train[np.where(y_train == 1)[0]]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f928ab17ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBExmEpARMRgKgEREYOpBEREDPZ/9X2z+utfe2MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f927e0eaf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9gUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f928ab0ab50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nADBQDgAAw/8H3RTE8rpm77oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9280e4df90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_test)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(y_dev)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(y_train)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist(y_train_res)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Deep Learning Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### dataset:\n",
    "1. x_train_res\n",
    "2. y_train_res\n",
    "3. x_dev\n",
    "4. y_dev\n",
    "5. x_test\n",
    "6. y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Convert the review from list of words to list of word dictionary index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tokens(docs):\n",
    "    tokens =[]\n",
    "    for i in docs:\n",
    "        lowers = i.lower()\n",
    "        #remove the punctuation using the character deletion step of translate\n",
    "        no_punctuation = lowers.translate(None, string.punctuation)\n",
    "        token = nltk.word_tokenize(no_punctuation)\n",
    "        tokens.extend(token)\n",
    "    return tokens\n",
    "\n",
    "tokens = get_tokens(x_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common(10000)\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic, rev_dict = build_dataset(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92553"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic['full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_dict[1461]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build sample data\n",
    "X_sample_ids = []\n",
    "for i in X_sample:\n",
    "    lowers = i.lower()\n",
    "    #remove the punctuation using the character deletion step of translate\n",
    "    no_punctuation = lowers.translate(None, string.punctuation)\n",
    "    token = nltk.word_tokenize(no_punctuation)\n",
    "    j=[dic[w] for w in token]\n",
    "    X_sample_ids.append(j)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build test data, note if word not in the dictionary, ignore\n",
    "X_test_ids = []\n",
    "for i in X_test:\n",
    "    lowers = i.lower()\n",
    "    #remove the punctuation using the character deletion step of translate\n",
    "    no_punctuation = lowers.translate(None, string.punctuation)\n",
    "    token = nltk.word_tokenize(no_punctuation)\n",
    "    j=[dic.get(w) for w in token if dic.get(w) is not None]   \n",
    "    X_test_ids.append(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For what I paid for two tutus is unbeatable anywhere!  I ordered a pink and turquios and they are vibrant and beautiful! The tutu is very full! Princess style! Not cheaply made! Not cheap materia! Obviously someone made these with love and care! I paid less than 7 bucks for a tutu I and I feel proud of my self for researching to the point of finding gold!Recommend 2-6 years!My daughter is two ! Wears size 4t and this skirt ( one size ) fit perfect and will probaly be able to accommodate her quickly growing waist for some time!\n",
      "[8, 86, 1, 611, 8, 134, 13856, 6, 5996, 1122, 1, 84, 3, 567, 2, 36860, 2, 12, 13, 1811, 2, 255, 0, 6132, 6, 26, 440, 3268, 194, 19, 1510, 90, 19, 259, 80013, 1183, 479, 90, 17, 20, 55, 2, 623, 1, 611, 326, 52, 415, 1225, 8, 3, 6132, 1, 2, 1, 115, 3151, 7, 11, 1969, 8, 5697, 4, 0, 580, 7, 813, 78856, 3345, 39652, 414, 6, 134, 460, 29, 6679, 2, 10, 615, 37, 29, 32, 96, 2, 42, 76260, 28, 338, 4, 1768, 206, 473, 2884, 225, 8, 87, 76]\n",
      "[ 0.875]\n",
      "Full and well stitched.  This tutu is a beautiful purple color that looks just like the picture.  It looks just adorable on our little fairy.\n",
      "[440, 2, 46, 2232, 10, 6132, 6, 3, 255, 823, 92, 14, 105, 33, 27, 0, 289, 5, 105, 33, 1188, 16, 455, 65, 10064]\n",
      "[ 1.]\n"
     ]
    }
   ],
   "source": [
    "print (X_sample[0])\n",
    "print (X_sample_ids[0])\n",
    "print (y_sample[0])\n",
    "\n",
    "print (X_test[0])\n",
    "print (X_test_ids[0])\n",
    "print (y_test[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Pad the sentence with differnt length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combine the list of words index and label into a dataframe\n",
    "train_df = pd.DataFrame(np.column_stack([X_sample_ids,y_sample]), \n",
    "                               columns=['list_words', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list_words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 86, 1, 611, 8, 134, 13856, 6, 5996, 1122, ...</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[440, 2, 46, 2232, 10, 6132, 6, 3, 255, 823, 9...</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3012, 1044, 2, 5, 6, 373, 25, 1038, 0, 80, 48...</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 1120, 1, 561, 10, 11, 1696, 9011, 3, 945, ...</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[55, 10, 494, 270, 22, 46, 141, 661, 610, 8284...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          list_words  label\n",
       "0  [8, 86, 1, 611, 8, 134, 13856, 6, 5996, 1122, ... 0.8750\n",
       "1  [440, 2, 46, 2232, 10, 6132, 6, 3, 255, 823, 9... 1.0000\n",
       "2  [3012, 1044, 2, 5, 6, 373, 25, 1038, 0, 80, 48... 0.5000\n",
       "3  [0, 1120, 1, 561, 10, 11, 1696, 9011, 3, 945, ... 1.0000\n",
       "4  [55, 10, 494, 270, 22, 46, 141, 661, 610, 8284... 0.0000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combine the list of words index and label into a dataframe\n",
    "test_df = pd.DataFrame(np.column_stack([X_test_ids,y_test]), \n",
    "                               columns=['list_words', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list_words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[440, 2, 46, 2232, 10, 6132, 6, 3, 255, 823, 9...</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3012, 1044, 2, 5, 6, 373, 25, 1038, 0, 80, 48...</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[10, 627, 6, 38, 8, 426, 20, 3, 164, 7, 494, 1...</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 3597, 860, 1571, 645, 23, 7944, 226, 86, 1...</td>\n",
       "      <td>0.7778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[48, 9, 0, 1815, 1, 24, 18154, 9, 1999, 8, 272...</td>\n",
       "      <td>0.4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          list_words  label\n",
       "0  [440, 2, 46, 2232, 10, 6132, 6, 3, 255, 823, 9... 1.0000\n",
       "1  [3012, 1044, 2, 5, 6, 373, 25, 1038, 0, 80, 48... 0.5000\n",
       "2  [10, 627, 6, 38, 8, 426, 20, 3, 164, 7, 494, 1... 0.5000\n",
       "3  [0, 3597, 860, 1571, 645, 23, 7944, 226, 86, 1... 0.7778\n",
       "4  [48, 9, 0, 1815, 1, 24, 18154, 9, 1999, 8, 272... 0.4000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [1, 27, 17, 85, 43, 52, 0, 11071, 1958, 1, 84,...\n",
      "1    [480, 39918, 2097, 136, 4, 2447, 443, 219, 88,...\n",
      "2    [1, 56, 8015, 3, 671, 14, 83841, 11, 2111, 20,...\n",
      "Name: list_words, dtype: object\n",
      "0   1.0000\n",
      "1   1.0000\n",
      "2   1.0000\n",
      "Name: label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "##this is not necessary\n",
    "class SimpleDataIterator():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.size = len(self.df)\n",
    "        self.epochs = 0\n",
    "        self.shuffle()\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "        self.cursor = 0\n",
    "\n",
    "    def next_batch(self, n):\n",
    "        if self.cursor+n-1 > self.size:\n",
    "            self.epochs += 1\n",
    "            self.shuffle()\n",
    "        res = self.df.ix[self.cursor:self.cursor+n-1]\n",
    "        self.cursor += n\n",
    "        return res['list_words'], res['label'] \n",
    "    \n",
    "data = SimpleDataIterator(train_df)\n",
    "a,b = data.next_batch(3)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##this helps to make sure each sentence have the same length (max_len)\n",
    "class PaddedDataIterator(SimpleDataIterator):\n",
    "    def next_batch(self, n, max_len):\n",
    "        if self.cursor+n > self.size:\n",
    "            self.epochs += 1\n",
    "            self.shuffle()\n",
    "#             self.max_len = max_len\n",
    "        res = self.df.ix[self.cursor:self.cursor+n-1]\n",
    "        self.cursor += n\n",
    "\n",
    "        # Pad sequences with 0s so they are all the same length\n",
    "        maxlen = max_len\n",
    "        x = np.zeros([n, maxlen], dtype=np.int32)\n",
    "        for i, x_i in enumerate(x):\n",
    "            l=len(res['list_words'].values[i]) ##list length\n",
    "            if l>maxlen: \n",
    "                x_i[:maxlen] = res['list_words'].values[i][:max_len]\n",
    "            else:\n",
    "                x_i[:l] = res['list_words'].values[i][:l]\n",
    "\n",
    "        return x, res['label'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_pad = PaddedDataIterator(train_df)\n",
    "data_pad_test = PaddedDataIterator(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1   55   10  637  505  108  166    3  171    7  190  145  116    2\n",
      "    55   21   41    0 2340   16   87    7   21   13 1292   15    0   88\n",
      "     6  595    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "0   1.0000\n",
      "Name: label, dtype: object\n",
      "[[  12 1845   68 1349    2  789   68  600   12   13   90    7   57   69\n",
      "  1258    2   22   54   28  195    9    3 1807 2810   12  128   20  344\n",
      "     1   57   55   21    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "0   0.5000\n",
      "Name: label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#sample call to get the data\n",
    "max_length = 100 \n",
    "batch_x, batch_y = PaddedDataIterator(train_df).next_batch(1,max_length)\n",
    "batch_x_test, batch_y_test = PaddedDataIterator(test_df).next_batch(1,max_length)\n",
    "print (batch_x)\n",
    "print (batch_y)\n",
    "print (batch_x_test)\n",
    "print (batch_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.build RNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/legu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:100: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1000, Minibatch Loss= 0.931417, Training Accuracy= 0.26800\n",
      "Iter 2000, Minibatch Loss= 0.940382, Training Accuracy= 0.25300\n",
      "Iter 3000, Minibatch Loss= 0.941001, Training Accuracy= 0.25000\n",
      "Iter 4000, Minibatch Loss= 0.902102, Training Accuracy= 0.27500\n",
      "Iter 5000, Minibatch Loss= 0.891506, Training Accuracy= 0.26500\n",
      "Iter 6000, Minibatch Loss= 0.889545, Training Accuracy= 0.26900\n",
      "Iter 7000, Minibatch Loss= 0.866880, Training Accuracy= 0.28600\n",
      "Iter 8000, Minibatch Loss= 0.891438, Training Accuracy= 0.25000\n",
      "Iter 9000, Minibatch Loss= 0.853439, Training Accuracy= 0.30100\n",
      "Iter 10000, Minibatch Loss= 0.846970, Training Accuracy= 0.29900\n",
      "Iter 11000, Minibatch Loss= 0.844638, Training Accuracy= 0.30500\n",
      "Iter 12000, Minibatch Loss= 0.815916, Training Accuracy= 0.33200\n",
      "Iter 13000, Minibatch Loss= 0.794854, Training Accuracy= 0.33400\n",
      "Iter 14000, Minibatch Loss= 0.795694, Training Accuracy= 0.34200\n",
      "Iter 15000, Minibatch Loss= 0.773681, Training Accuracy= 0.36200\n",
      "Iter 16000, Minibatch Loss= 0.780776, Training Accuracy= 0.36000\n",
      "Iter 17000, Minibatch Loss= 0.757538, Training Accuracy= 0.37300\n",
      "Iter 18000, Minibatch Loss= 0.762160, Training Accuracy= 0.38600\n",
      "Iter 19000, Minibatch Loss= 0.734666, Training Accuracy= 0.41500\n",
      "Iter 20000, Minibatch Loss= 0.716573, Training Accuracy= 0.44400\n",
      "Iter 21000, Minibatch Loss= 0.711524, Training Accuracy= 0.48200\n",
      "Iter 22000, Minibatch Loss= 0.716826, Training Accuracy= 0.49200\n",
      "Iter 23000, Minibatch Loss= 0.686421, Training Accuracy= 0.54100\n",
      "Iter 24000, Minibatch Loss= 0.704492, Training Accuracy= 0.53800\n",
      "Iter 25000, Minibatch Loss= 0.672911, Training Accuracy= 0.59000\n",
      "Iter 26000, Minibatch Loss= 0.658514, Training Accuracy= 0.62900\n",
      "Iter 27000, Minibatch Loss= 0.645824, Training Accuracy= 0.67300\n",
      "Iter 28000, Minibatch Loss= 0.644501, Training Accuracy= 0.67800\n",
      "Iter 29000, Minibatch Loss= 0.637273, Training Accuracy= 0.70500\n",
      "Iter 30000, Minibatch Loss= 0.616452, Training Accuracy= 0.73700\n",
      "Iter 31000, Minibatch Loss= 0.621278, Training Accuracy= 0.75100\n",
      "Iter 32000, Minibatch Loss= 0.597906, Training Accuracy= 0.77300\n",
      "Iter 33000, Minibatch Loss= 0.597016, Training Accuracy= 0.76600\n",
      "Iter 34000, Minibatch Loss= 0.596783, Training Accuracy= 0.76900\n",
      "Iter 35000, Minibatch Loss= 0.602212, Training Accuracy= 0.78800\n",
      "Iter 36000, Minibatch Loss= 0.608001, Training Accuracy= 0.78300\n",
      "Iter 37000, Minibatch Loss= 0.600461, Training Accuracy= 0.78800\n",
      "Iter 38000, Minibatch Loss= 0.606196, Training Accuracy= 0.78200\n",
      "Iter 39000, Minibatch Loss= 0.632137, Training Accuracy= 0.78200\n",
      "Iter 40000, Minibatch Loss= 0.607089, Training Accuracy= 0.77700\n",
      "Iter 41000, Minibatch Loss= 0.579795, Training Accuracy= 0.82200\n",
      "Iter 42000, Minibatch Loss= 0.575120, Training Accuracy= 0.81200\n",
      "Iter 43000, Minibatch Loss= 0.573341, Training Accuracy= 0.82000\n",
      "Iter 44000, Minibatch Loss= 0.599143, Training Accuracy= 0.81700\n",
      "Iter 45000, Minibatch Loss= 0.602557, Training Accuracy= 0.80900\n",
      "Iter 46000, Minibatch Loss= 0.604408, Training Accuracy= 0.79400\n",
      "Iter 47000, Minibatch Loss= 0.585909, Training Accuracy= 0.80900\n",
      "Iter 48000, Minibatch Loss= 0.556823, Training Accuracy= 0.83200\n",
      "Iter 49000, Minibatch Loss= 0.603165, Training Accuracy= 0.79800\n",
      "Iter 50000, Minibatch Loss= 0.578970, Training Accuracy= 0.80400\n",
      "Iter 51000, Minibatch Loss= 0.580756, Training Accuracy= 0.82200\n",
      "Iter 52000, Minibatch Loss= 0.556957, Training Accuracy= 0.83900\n",
      "Iter 53000, Minibatch Loss= 0.565530, Training Accuracy= 0.82300\n",
      "Iter 54000, Minibatch Loss= 0.576549, Training Accuracy= 0.81000\n",
      "Iter 55000, Minibatch Loss= 0.536255, Training Accuracy= 0.83900\n",
      "Iter 56000, Minibatch Loss= 0.570653, Training Accuracy= 0.81300\n",
      "Iter 57000, Minibatch Loss= 0.550237, Training Accuracy= 0.82800\n",
      "Iter 58000, Minibatch Loss= 0.561397, Training Accuracy= 0.82300\n",
      "Iter 59000, Minibatch Loss= 0.555032, Training Accuracy= 0.83900\n",
      "Iter 60000, Minibatch Loss= 0.573507, Training Accuracy= 0.82700\n",
      "Iter 61000, Minibatch Loss= 0.551024, Training Accuracy= 0.83100\n",
      "Iter 62000, Minibatch Loss= 0.576448, Training Accuracy= 0.82500\n",
      "Iter 63000, Minibatch Loss= 0.573952, Training Accuracy= 0.80600\n",
      "Iter 64000, Minibatch Loss= 0.583966, Training Accuracy= 0.81400\n",
      "Iter 65000, Minibatch Loss= 0.561372, Training Accuracy= 0.82600\n",
      "Iter 66000, Minibatch Loss= 0.588686, Training Accuracy= 0.82200\n",
      "Iter 67000, Minibatch Loss= 0.550429, Training Accuracy= 0.82800\n",
      "Iter 68000, Minibatch Loss= 0.571007, Training Accuracy= 0.81900\n",
      "Iter 69000, Minibatch Loss= 0.569601, Training Accuracy= 0.82000\n",
      "Iter 70000, Minibatch Loss= 0.519164, Training Accuracy= 0.85500\n",
      "Iter 71000, Minibatch Loss= 0.551613, Training Accuracy= 0.83400\n",
      "Iter 72000, Minibatch Loss= 0.563147, Training Accuracy= 0.82300\n",
      "Iter 73000, Minibatch Loss= 0.556735, Training Accuracy= 0.83200\n",
      "Iter 74000, Minibatch Loss= 0.553031, Training Accuracy= 0.83100\n",
      "Iter 75000, Minibatch Loss= 0.565023, Training Accuracy= 0.81000\n",
      "Iter 76000, Minibatch Loss= 0.538806, Training Accuracy= 0.84500\n",
      "Iter 77000, Minibatch Loss= 0.556477, Training Accuracy= 0.84100\n",
      "Iter 78000, Minibatch Loss= 0.574180, Training Accuracy= 0.81700\n",
      "Iter 79000, Minibatch Loss= 0.567660, Training Accuracy= 0.82500\n",
      "Iter 80000, Minibatch Loss= 0.555128, Training Accuracy= 0.82900\n",
      "Iter 81000, Minibatch Loss= 0.564096, Training Accuracy= 0.83000\n",
      "Iter 82000, Minibatch Loss= 0.543484, Training Accuracy= 0.85100\n",
      "Iter 83000, Minibatch Loss= 0.578429, Training Accuracy= 0.79500\n",
      "Iter 84000, Minibatch Loss= 0.551320, Training Accuracy= 0.83800\n",
      "Iter 85000, Minibatch Loss= 0.531805, Training Accuracy= 0.83700\n",
      "Iter 86000, Minibatch Loss= 0.539410, Training Accuracy= 0.84000\n",
      "Iter 87000, Minibatch Loss= 0.571830, Training Accuracy= 0.81100\n",
      "Iter 88000, Minibatch Loss= 0.544718, Training Accuracy= 0.83800\n",
      "Iter 89000, Minibatch Loss= 0.563417, Training Accuracy= 0.80800\n",
      "Iter 90000, Minibatch Loss= 0.571106, Training Accuracy= 0.82200\n",
      "Iter 91000, Minibatch Loss= 0.532051, Training Accuracy= 0.85200\n",
      "Iter 92000, Minibatch Loss= 0.552093, Training Accuracy= 0.83100\n",
      "Iter 93000, Minibatch Loss= 0.567971, Training Accuracy= 0.81500\n",
      "Iter 94000, Minibatch Loss= 0.554480, Training Accuracy= 0.82200\n",
      "Iter 95000, Minibatch Loss= 0.557926, Training Accuracy= 0.83200\n",
      "Iter 96000, Minibatch Loss= 0.535081, Training Accuracy= 0.83400\n",
      "Iter 97000, Minibatch Loss= 0.538526, Training Accuracy= 0.84700\n",
      "Iter 98000, Minibatch Loss= 0.546775, Training Accuracy= 0.84100\n",
      "Iter 99000, Minibatch Loss= 0.534848, Training Accuracy= 0.84300\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/legu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:123: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.834134\n",
      "Testing cost: 0.556403\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "Long Short Term Memory paper: http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "# Import MNIST data\n",
    "\n",
    "\n",
    "'''\n",
    "To classify images using a recurrent neural network, we consider every image\n",
    "row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\n",
    "handle 28 sequences of 28 steps for every sample.\n",
    "'''\n",
    "######################## \n",
    "### MODEL PARAMETERS ###\n",
    "######################## \n",
    "\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 1000\n",
    "display_step = 1\n",
    "sentence_size = 150\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 10  \n",
    "n_steps = sentence_size/n_input # timesteps\n",
    "n_hidden = 20 # hidden layer num of features\n",
    "n_classes = 2  \n",
    "\n",
    "\n",
    "#################################\n",
    "### PLACEHOLDER AND VARIABLE ###\n",
    "#################################\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "######################## \n",
    "### DEFINE RNN MODEL ###\n",
    "######################## \n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, n_steps, 1)\n",
    "\n",
    "    \n",
    "    with tf.variable_scope(\"first_lstm66\"):\n",
    "        # Define a lstm cell with tensorflow\n",
    "        lstm_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "        # Get lstm cell output\n",
    "        outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "pred = RNN(x, weights, biases)\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "### LOSS AND OPTIMIZATION ###\n",
    "#############################\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    \n",
    "##################\n",
    "### EVALUATION ###\n",
    "################## \n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "#################\n",
    "### RUN GRAPH ###\n",
    "#################\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    iters=[]\n",
    "    costs=[]\n",
    "    accs=[]\n",
    "\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        \n",
    "        ##########################\n",
    "        ### GENERATE BATCH X,Y ###\n",
    "        ##########################\n",
    "        batch_x, batch_y_1 = PaddedDataIterator(train_df).next_batch(batch_size,sentence_size)\n",
    "        batch_y = np.concatenate((batch_y_1.reshape([-1,1]), 1-batch_y_1.reshape([-1,1])), axis=1)\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "        \n",
    "        \n",
    "        ################\n",
    "        ### TRAINING ###\n",
    "        ################\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        \n",
    "        #################\n",
    "        ### REPORTING ###\n",
    "        #################\n",
    "        \n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy, loss\n",
    "            acc,loss = sess.run([accuracy,cost], feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "            iters.append(step*batch_size)\n",
    "            costs.append(loss)\n",
    "            accs.append(acc)\n",
    "#             print( sess.run(pred, feed_dict={x: batch_x, y: batch_y}))\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    ##########################\n",
    "    ### EVALUATE TEST DATA ###\n",
    "    ##########################    \n",
    "    \n",
    "    batch_x_test_1, batch_y_1_test = PaddedDataIterator(test_df).next_batch(26015,sentence_size)\n",
    "    batch_x_test = batch_x_test_1.reshape([-1,n_steps, n_input])\n",
    "    batch_y_test = np.concatenate((batch_y_1_test.reshape([-1,1]), 1-batch_y_1_test.reshape([-1,1])), axis=1)\n",
    "    test_acc, test_cost = sess.run([accuracy, cost], feed_dict={x: batch_x_test, y: batch_y_test})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAENCAYAAAAc1VI3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb0b8886c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAENCAYAAAAc1VI3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOOQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb0b8890110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.834134\n",
      "Testing cost: 0.556403\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple demo of a scatter plot.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#     accs=[]\n",
    "    \n",
    "x = iters\n",
    "y = costs\n",
    "z = accs\n",
    "\n",
    "plt.scatter(x, y )\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('cost')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(x, z)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()\n",
    "\n",
    "print (\"Testing Accuracy:\",test_acc)\n",
    "print(\"Testing cost:\",test_cost)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_x, batch_y = PaddedDataIterator(train_df).next_batch(batch_size,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   5,  176,   34,   33,   55,  473,    5,  371,   68,  111,    4,\n",
       "        2523,  133,    5,   34,  371,    3,  140,  539,    2,   55,    1,\n",
       "        2409,   22,    1,   64,  210,   20,  237,    5,  175,  335,   21,\n",
       "           5,  193,  271,    5, 1097,  326,   53,    1,  216,   57,    9,\n",
       "        1349,    1,   17,   10,  150,   15,  266,    4,  213,   31, 2480,\n",
       "           9,  849,    1,   17,   15, 2183, 1508,  426,   11,   15,  352,\n",
       "          13, 2397,  432,    4,    3,  179, 1624,   40,    0, 2087,  663,\n",
       "           4,  891,  819,    2,  215,  192,   11,  512,    0,  266,  822,\n",
       "           7,    3,   62,  207,   23,    1,   43,    2,  612,    5,  125,\n",
       "          23],\n",
       "       [   1,  182,   10,   91,    3,   62,  100,    3,  160,  329,  136,\n",
       "          12,    1,   78,  451,   13,    5,    1,  263,    2,  968,    5,\n",
       "           1,  124,    5,   16, 1273,    4, 1381,   36,   43,  131, 2129,\n",
       "        1394,    0, 1723,    4,   17,  101,  692,    0, 1882,   11,    0,\n",
       "        1361, 2415, 2062, 1912,   16,    0,  732,    5,  839,   12,    0,\n",
       "         695,    7,   20, 1188,   23,    6,  220,  968,    5,   21,    3,\n",
       "         110,  423,   99,  148,  451,   13, 2383, 2179,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [ 182,   10,  242,    8,   15,  194,    2,  313,  123,  601,  563,\n",
       "          11,    4,    5,  389,   14,    0,  538,    9,    0,  173,  563,\n",
       "         111,    0, 1992,  551,  882,  125,  638,    1,   72,    5,   41,\n",
       "          33,  251,   22,    6,   60,  124,  327,  421,    0,  242,   14,\n",
       "          22,    6,  112,    2,  124,  563,   11,   92,   40,   15,  194,\n",
       "          47,    6,   41,   17,    2, 2361,   16,   24,  165,  551,   26,\n",
       "         954,  429,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [  10,   39, 1157, 1910,    4,  265, 2389,  125,    2,    3, 1613,\n",
       "         234, 1267,    7, 1455,    2,   35,    3,  179, 1495,   52,  169,\n",
       "        2577,   11, 2478, 2181, 1830,    4,   79,    3, 1563, 1538,   26,\n",
       "        1244,   27,  159,  440,  159,   14, 1975,   22,    6,  112,    3,\n",
       "          62,   50,  817,  130,   13,    0, 2066,  146, 1874,  196,   12,\n",
       "          63,  905,    0,  519,    7,    3,  440, 1450,   99,   51, 1502,\n",
       "         629,    9,    3, 1015,   39,   13,    3,  519,  196,    0,  449,\n",
       "           7,  553, 2402,  168,    0,  151, 1632,  114, 2212,    4, 2238,\n",
       "         198,    0,   65,   96,  410,    9,  121,    5,  212,  435,   14,\n",
       "          27],\n",
       "       [   1,  182,   10,  103,    2,  406,   96,  427,  171,  252,  370,\n",
       "          97,  461,   16,  439,  128,   34,  114,  472,    4,    0,  103,\n",
       "          18,    3,  493, 1120,   15,  427,  104,   20,   17,   31,  609,\n",
       "          23,   10, 1319,  103,  104,   27,  338,   68,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [ 478, 1983,   18,   42,    1, 2514,  365,    4,   45,  238, 2338,\n",
       "          78,  589,   13,    0, 2435,  155, 2322,  194,  566,    5,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [  74,  238,    1,  114, 1981,   42,    1,  328,    4,  492,    5,\n",
       "          11,  161,  784,    1, 1291,    4,   48,    2,   15,  767,    4,\n",
       "         533,   21,   68,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [ 110,   10,   16,  333,  546,  439, 1131,   52, 1845,   97,   24,\n",
       "         663,   26,  277,    8,  195,   26, 1115,    1,  745,  205,    5,\n",
       "         389,  209,  213,   24,  549,   43,   15,  195,  405,  860,    4,\n",
       "         426,   11,    5,  252,  225,   97,    0,  461,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [   2,   15,   80,    9, 1787,   92,   19,   49,   96, 2589,  142,\n",
       "         215,    0,  579,   52, 1646,    3,  531, 2544,  404,  120,    7,\n",
       "           0,   39,  233,    5,    7,   20,   32,  391,    5,  249,   79,\n",
       "         500,   27,  111,   57,    9,   32,  190,  845,  642,    1,  165,\n",
       "         301,  211,    4,   79,    0, 2473,  500,  233,  422,  559,   37,\n",
       "           0, 2317,    9,    3,  815,   14,   10,   31,  534,    5,    2,\n",
       "           3,  381,  146,   77,  239,   33,  878,    2, 1862,   76,  380,\n",
       "           8, 1081,    5,  273, 1316,    7,    0,  465,   12,  598,    0,\n",
       "        1483,    9,  138,  503,  880,    2,  582, 1431,  812, 1533,  450,\n",
       "          10],\n",
       "       [  10,   18,    3,   32,  446,  426,   12,    1,  110,   11, 2123,\n",
       "         243,    7, 1373, 2559,   23,    5,  193,   20,  435,   97,    3,\n",
       "         549,   14,  268,    2,  157,    3, 1758,   26,    3, 1498,    8,\n",
       "         575, 2345,  591,  877,  574,  244, 2572,   30,  190,  313, 1213,\n",
       "        1776, 2340,   13, 1249,   30,  313, 1948, 1077,   26,  917,   22,\n",
       "           6, 1865,  207,  266,  103,   12,   30,   33, 1310,   59, 1795,\n",
       "           3,  681,  426,   11, 2225,  649,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0]], dtype=int32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_x, batch_y = PaddedDataIterator(train_df).next_batch(batch_size,100)\n",
    "batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "\n",
    "x = tf.unstack(x, n_steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'unstack_5:0' shape=(?, 10) dtype=float32>,\n",
       " <tf.Tensor 'unstack_5:1' shape=(?, 10) dtype=float32>,\n",
       " <tf.Tensor 'unstack_5:2' shape=(?, 10) dtype=float32>,\n",
       " <tf.Tensor 'unstack_5:3' shape=(?, 10) dtype=float32>,\n",
       " <tf.Tensor 'unstack_5:4' shape=(?, 10) dtype=float32>,\n",
       " <tf.Tensor 'unstack_5:5' shape=(?, 10) dtype=float32>,\n",
       " <tf.Tensor 'unstack_5:6' shape=(?, 10) dtype=float32>,\n",
       " <tf.Tensor 'unstack_5:7' shape=(?, 10) dtype=float32>,\n",
       " <tf.Tensor 'unstack_5:8' shape=(?, 10) dtype=float32>,\n",
       " <tf.Tensor 'unstack_5:9' shape=(?, 10) dtype=float32>]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.unstack(x, n_steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##define variables \n",
    "n_hidden = 10 \n",
    "with tf.variable_scope(\"softmax\"):\n",
    "    W_out_ = tf.Variable(tf.random_uniform([n_hidden,1], 0.0, 1.0), name=\"W_out_\")\n",
    "    b_out_ = tf.Variable(tf.zeros([1], dtype=tf.float32) ,name=\"b_out_\")\n",
    "\n",
    "with tf.variable_scope(\"recurrent\"):\n",
    "    rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "    initial_h_ = self.cell_.zero_state(self.batch_size_,dtype=tf.float32)\n",
    "    outputs, self.final_h_ = tf.nn.dynamic_rnn(self.cell_, inputs=self.x_,initial_state=self.initial_h_, sequence_length=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MakeFancyRNNCell(H, keep_prob, num_layers=1):\n",
    "    \"\"\"Make a fancy RNN cell.\n",
    "\n",
    "    Use tf.nn.rnn_cell functions to construct an LSTM cell.\n",
    "    Initialize forget_bias=0.0 for better training.\n",
    "\n",
    "    Args:\n",
    "      H: hidden state size\n",
    "      keep_prob: dropout keep prob (same for input and output)\n",
    "      num_layers: number of cell layers\n",
    "\n",
    "    Returns:\n",
    "      (tf.nn.rnn_cell.RNNCell) multi-layer LSTM cell with dropout\n",
    "    \"\"\"\n",
    "    cells = []\n",
    "    for _ in xrange(num_layers):\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(H, forget_bias=0.0)\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        cell, input_keep_prob=keep_prob, output_keep_prob=keep_prob)\n",
    "        cells.append(cell)\n",
    "    return tf.contrib.rnn.MultiRNNCell(cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##have to fix here!!!\n",
    "def RNN(x):\n",
    "    n_hidden = 10 \n",
    "    with tf.variable_scope(\"softmax\"):\n",
    "        W_out_ = tf.Variable(tf.random_uniform([n_hidden,1], 0.0, 1.0), name=\"W_out_\")\n",
    "        b_out_ = tf.Variable(tf.zeros([1], dtype=tf.float32) ,name=\"b_out_\")\n",
    "    # reshape to [1, n_input]\n",
    "    n_input = len(x)\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "\n",
    "    # Generate a n_input-element sequence of inputs\n",
    "    # (eg. [had] [a] [general] -> [20] [6] [33])\n",
    "    x = tf.split(x,n_input,1)\n",
    "#     print x\n",
    "    # 1-layer LSTM with n_hidden units.\n",
    "#     with tf.variable_scope('cell_def'):\n",
    "#         lstm_cell = MakeFancyRNNCell(H=n_hidden,keep_prob=1)\n",
    "    lstm_cell = tf.contrib.rnn.core_rnn_cell.BasicLSTMCell(n_hidden, forget_bias=0.0)\n",
    "#     print x\n",
    "    # generate prediction\n",
    "\n",
    "    \n",
    "#     with tf.variable_scope('rnn_def',reuse=True):\n",
    "    initial_h_ = lstm_cell.zero_state(1,dtype=tf.int32)\n",
    "    outputs,final_h_ = tf.contrib.rnn.static_rnn(lstm_cell, x,dtype=tf.int32)\n",
    "            \n",
    "            \n",
    "\n",
    "    # there are n_input outputs but\n",
    "    # we only want the last output\n",
    "    return tf.matmul(outputs[-1], W_out_) + b_out_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'static_rnn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-320bf1dbf5de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sample_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Loss and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-c600588cd114>\u001b[0m in \u001b[0;36mRNN\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#     with tf.variable_scope('rnn_def',reuse=True):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0minitial_h_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_h_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_rnn_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'static_rnn'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "\n",
    "learning_rate =0.1\n",
    "pred = RNN(X_sample_ids[0])\n",
    "\n",
    "# Loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_sample[0]))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, loss, onehot_pred = session.run([optimizer, cost, pred], \n",
    "                                        feed_dict={x: symbols_in_keys, y: symbols_out_onehot})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60843,)\n",
      "(26177,)\n",
      "(60843, 1)\n",
      "(26177, 1)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_sample = nonnan_doc_clean[0:100]\n",
    "y_sample = y[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "This is a great tutu and at a really great price. It doesn't look cheap at all. I'm so glad I looked on Amazon and found such an affordable tutu that isn't made poorly. A++\n",
      "[ 0.875]\n"
     ]
    }
   ],
   "source": [
    "print len(X_sample[0].split())\n",
    "print X_sample[0]\n",
    "print y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.__getattr__('brown').words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = X_sample[0].split()\n",
    "bi = utils.batch_generator(np.array(X_sample[0].split()), batch_size=1, max_time=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['For' 'what' 'I' 'paid' 'for' 'two' 'tutus' 'is' 'unbeatable' 'anywhere!'\n",
      "  'I' 'ordered' 'a' 'pink' 'and' 'turquios' 'and' 'they' 'are' 'vibrant'\n",
      "  'and' 'beautiful!' 'The' 'tutu' 'is' 'very' 'full!' 'Princess' 'style!'\n",
      "  'Not' 'cheaply' 'made!' 'Not' 'cheap' 'materia!' 'Obviously' 'someone'\n",
      "  'made' 'these' 'with' 'love' 'and' 'care!' 'I' 'paid' 'less' 'than' '7'\n",
      "  'bucks' 'for' 'a' 'tutu' 'I' 'and' 'I' 'feel' 'proud' 'of' 'my' 'self'\n",
      "  'for' 'researching' 'to' 'the' 'point' 'of' 'finding' 'gold!Recommend'\n",
      "  '2-6' 'years!My' 'daughter' 'is' 'two' '!' 'Wears' 'size' '4t' 'and'\n",
      "  'this' 'skirt' '(' 'one' 'size' ')' 'fit' 'perfect' 'and' 'will'\n",
      "  'probaly' 'be' 'able' 'to' 'accommodate' 'her' 'quickly' 'growing'\n",
      "  'waist' 'for' 'some']]\n",
      "[ 0.875]\n"
     ]
    }
   ],
   "source": [
    "for i, (w,y) in enumerate(bi):\n",
    "    print w\n",
    "    print y_sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rnnlm' from 'rnnlm.py'>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rnnlm\n",
    "# import rnnlm_test\n",
    "reload(rnnlm)\n",
    "# reload(rnnlm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(lm, session, batch_iterator,\n",
    "              train=False, verbose=False,\n",
    "              tick_s=10, learning_rate=0.1):\n",
    "    start_time = time.time()\n",
    "    tick_time = start_time  # for showing status\n",
    "    total_cost = 0.0  # total cost, summed over all words\n",
    "    total_batches = 0\n",
    "    total_words = 0\n",
    "\n",
    "    if train:\n",
    "        train_op = lm.train_step_\n",
    "        use_dropout = True\n",
    "        loss = lm.train_loss_\n",
    "    else:\n",
    "        train_op = tf.no_op()\n",
    "        use_dropout = False  # no dropout at test time\n",
    "        loss = lm.loss_  # true loss, if train_loss is an approximation\n",
    "\n",
    "    for i, (w, y) in enumerate(batch_iterator):\n",
    "        cost = 0.0\n",
    "        # At first batch in epoch, get a clean intitial state.\n",
    "        if i == 0:\n",
    "            h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "\n",
    "        #### YOUR CODE HERE ####\n",
    "        \n",
    "        feed_dict = {lm.input_w_:w,\n",
    "                 lm.target_y_:y,\n",
    "                 lm.learning_rate_:learning_rate,\n",
    "                 lm.initial_h_ : h}\n",
    "            \n",
    "        cost, _, h = session.run([loss, train_op,lm.final_h_],\n",
    "                       feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "        #### END(YOUR CODE) ####\n",
    "        total_cost += cost\n",
    "        total_batches = i + 1\n",
    "        total_words += w.size  # w.size = batch_size * max_time\n",
    "\n",
    "        ##\n",
    "        # Print average loss-so-far for epoch\n",
    "        # If using train_loss_, this may be an underestimate.\n",
    "        if verbose and (time.time() - tick_time >= tick_s):\n",
    "            avg_cost = total_cost / total_batches\n",
    "            avg_wps = total_words / (time.time() - start_time)\n",
    "            print \"[batch %d]: seen %d words at %d wps, loss = %.3f\" % (\n",
    "                i, total_words, avg_wps, avg_cost)\n",
    "            tick_time = time.time()  # reset time ticker\n",
    "\n",
    "    return total_cost / total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V=1000\n",
    "max_time = 20\n",
    "batch_size = 50\n",
    "learning_rate = 0.5\n",
    "num_epochs = 5\n",
    "\n",
    "# Model parameters\n",
    "model_params = dict(V=100, \n",
    "                    H=100, \n",
    "                    softmax_ns=200,\n",
    "                    num_layers=1)\n",
    "\n",
    "# TF_SAVEDIR = \"tf_saved\"\n",
    "# checkpoint_filename = os.path.join(TF_SAVEDIR, \"rnnlm\")\n",
    "# trained_filename = os.path.join(TF_SAVEDIR, \"rnnlm_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension must be 2 but is 3 for 'recurrent/transpose' (op: 'Transpose') with input shapes: [?,100], [3].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-576b79a3ba51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnnlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRNNLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildCoreGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildTrainGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/legu/266project/w266-final-project/rnnlm.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/legu/266project/w266-final-project/rnnlm.py\u001b[0m in \u001b[0;36mBuildCoreGraph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_h_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_h_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_h_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/legu/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/rnn.pyc\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;31m# (B,T,D) => (T,B,D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m     flat_input = tuple(array_ops.transpose(input_, [1, 0, 2])\n\u001b[0;32m--> 497\u001b[0;31m                        for input_ in flat_input)\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m   \u001b[0mparallel_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_iterations\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/legu/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/rnn.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((input_,))\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;31m# (B,T,D) => (T,B,D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m     flat_input = tuple(array_ops.transpose(input_, [1, 0, 2])\n\u001b[0;32m--> 497\u001b[0;31m                        for input_ in flat_input)\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m   \u001b[0mparallel_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_iterations\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/legu/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(a, perm, name)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/legu/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.pyc\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(x, perm, name)\u001b[0m\n\u001b[1;32m   3719\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3720\u001b[0m   \"\"\"\n\u001b[0;32m-> 3721\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transpose\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3722\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/legu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    766\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    767\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/legu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2336\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2338\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2339\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/legu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1717\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/legu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/legu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/legu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension must be 2 but is 3 for 'recurrent/transpose' (op: 'Transpose') with input shapes: [?,100], [3]."
     ]
    }
   ],
   "source": [
    "# Will print status every this many seconds\n",
    "import rnnlm\n",
    "# import rnnlm_test\n",
    "reload(rnnlm)\n",
    "print_interval = 5\n",
    "\n",
    "# Clear old log directory\n",
    "shutil.rmtree(\"tf_summaries\", ignore_errors=True)\n",
    "\n",
    "lm = rnnlm.RNNLM(**model_params)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildTrainGraph()\n",
    "\n",
    "# Explicitly add global initializer and variable saver to LM graph\n",
    "with lm.graph.as_default():\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "# Clear old log directory\n",
    "# shutil.rmtree(TF_SAVEDIR, ignore_errors=True)\n",
    "# if not os.path.isdir(TF_SAVEDIR):\n",
    "#     os.makedirs(TF_SAVEDIR)\n",
    "\n",
    "with tf.Session(graph=lm.graph) as session:\n",
    "    # Seed RNG for repeatability\n",
    "    tf.set_random_seed(42)\n",
    "\n",
    "    session.run(initializer)\n",
    "\n",
    "    for epoch in xrange(1,num_epochs+1):\n",
    "        t0_epoch = time.time()\n",
    "#         bi = utils.batch_generator(train_ids, batch_size, max_time)\n",
    "        corpus = X_sample[0].split()\n",
    "        bi = utils.batch_generator(np.array(X_sample[0].split()), batch_size=1, max_time=100)\n",
    "        for i, (w,y) in enumerate(bi):\n",
    "            w1=w\n",
    "            \n",
    "        bi= (w1,y_sample[y])\n",
    "        print \"[epoch %d] Starting epoch %d\" % (epoch, epoch)\n",
    "        #### YOUR CODE HERE ####\n",
    "        # Run a training epoch.\n",
    "        cost = run_epoch(lm, session, bi, \n",
    "                     learning_rate=learning_rate, train=True, \n",
    "                     verbose=False, tick_s=3600)\n",
    "\n",
    "        #### END(YOUR CODE) ####\n",
    "        print \"[epoch %d] Completed in %s\" % (epoch, utils.pretty_timedelta(since=t0_epoch))\n",
    "    \n",
    "        # Save a checkpoint\n",
    "        saver.save(session, checkpoint_filename, global_step=epoch)\n",
    "    \n",
    "        ##\n",
    "        # score_dataset will run a forward pass over the entire dataset\n",
    "        # and report perplexity scores. This can be slow (around 1/2 to \n",
    "        # 1/4 as long as a full epoch), so you may want to comment it out\n",
    "        # to speed up training on a slow machine. Be sure to run it at the \n",
    "        # end to evaluate your score.\n",
    "        print (\"[epoch %d]\" % epoch),\n",
    "        #score_dataset(lm, session, train_ids, name=\"Train set\")\n",
    "        print (\"[epoch %d]\" % epoch),\n",
    "        score_dataset(lm, session, test_ids, name=\"Test set\")\n",
    "        print \"\"\n",
    "    \n",
    "    # Save final model\n",
    "    saver.save(session, trained_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/legu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "\n",
    "corpus = nltk.corpus.brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vocabulary\n",
      "  Downloading Vocabulary-1.0.4.tar.gz\n",
      "Collecting requests==2.13.0 (from vocabulary)\n",
      "  Downloading requests-2.13.0-py2.py3-none-any.whl (584kB)\n",
      "\u001b[K    100% |████████████████████████████████| 593kB 408kB/s \n",
      "\u001b[?25hCollecting mock==2.0.0 (from vocabulary)\n",
      "  Downloading mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 1.9MB/s \n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): funcsigs>=1; python_version < \"3.3\" in /Users/legu/anaconda/lib/python2.7/site-packages (from mock==2.0.0->vocabulary)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.9 in /Users/legu/anaconda/lib/python2.7/site-packages (from mock==2.0.0->vocabulary)\n",
      "Collecting pbr>=0.11 (from mock==2.0.0->vocabulary)\n",
      "  Downloading pbr-3.1.1-py2.py3-none-any.whl (99kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 1.2MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: vocabulary\n",
      "  Running setup.py bdist_wheel for vocabulary ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/legu/Library/Caches/pip/wheels/36/6c/c0/92bb20f79402d055c3bce3e89d9f2cce5d6937bc2aadc0fb45\n",
      "Successfully built vocabulary\n",
      "Installing collected packages: requests, pbr, mock, vocabulary\n",
      "  Found existing installation: requests 2.11.1\n",
      "    Uninstalling requests-2.11.1:\n",
      "      Successfully uninstalled requests-2.11.1\n",
      "Successfully installed mock-2.0.0 pbr-3.1.1 requests-2.13.0 vocabulary-1.0.4\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'Vocabulary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-385fd0cf2b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# train_sents, test_sents = utils.get_train_test_sents(corpus, split=0.8, shuffle=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Train set vocabulary: %d words\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'Vocabulary'"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import vocabulary\n",
    "# train_sents, test_sents = utils.get_train_test_sents(corpus, split=0.8, shuffle=True)\n",
    "vocab = vocabulary.Vocabulary(utils.canonicalize_word(w) for w in utils.flatten(corpus))\n",
    "print \"Train set vocabulary: %d words\" % vocab.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
